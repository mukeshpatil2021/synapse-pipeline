{
	"name": "dq_chk_Notebook",
	"properties": {
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "daiGcoSp",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "45ca45a2-e01b-4816-807a-3e370b80273a"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/9a45fe97-6e0f-41e6-8e18-c61706819d17/resourceGroups/RG_DAI_GCO_POC/providers/Microsoft.Synapse/workspaces/dai-gcoanalytics-synapse-workspace/bigDataPools/daiGcoSp",
				"name": "daiGcoSp",
				"type": "Spark",
				"endpoint": "https://dai-gcoanalytics-synapse-workspace.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/daiGcoSp",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.1",
				"nodeCount": 10,
				"cores": 4,
				"memory": 28,
				"extraHeader": null
			}
		},
		"cells": [
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"outputs_hidden": true
					},
					"tags": [
						"parameters"
					]
				},
				"source": [
					"table_name = \"\"\r\n",
					"schema_name = \"\"\r\n",
					"LOG_ID = \"\"\r\n",
					"PARAMETER_ID = \"\"\r\n",
					"DataFactory_Name = \"\"\r\n",
					"pipeline_Name = \"\"\r\n",
					"pipeline_run_id = \"\"\r\n",
					"Source = \"\"\r\n",
					"Destination = \"\"\r\n",
					"trigger_type = \"\"\r\n",
					"trigger_id = \"\"\r\n",
					"trigger_name = \"\"\r\n",
					"trigger_start_time = \"\"\r\n",
					"rowsCopied = \"\"\r\n",
					"dataRead = \"\"\r\n",
					"No_ParallelCopies = \"\"\r\n",
					"copyDuration_in_secs = \"\"\r\n",
					"effectiveegrationRuntime = \"\"\r\n",
					"Source_Type = \"\"\r\n",
					"Sink_Type = \"\"\r\n",
					"Execution_Status = \"\"\r\n",
					"CopyActivity_Start_Time = \"\"\r\n",
					"CopyActivity_End_Time = \"\"\r\n",
					"CopyActivity_queuingDuration_in_secs = \"\"\r\n",
					"CopyActivity_transferDuration_in_secs = \"\"\r\n",
					"df_count = \"\"\r\n",
					"df_metrics = \"\""
				],
				"attachments": null,
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"import datetime\r\n",
					"partition_date = str(datetime.datetime.now().strftime(\"%Y%m%d\"))"
				],
				"attachments": null,
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"dq_in_path = 'abfss://daigcoanalyticsstorage@daigcoanalyticsstorage.dfs.core.windows.net/staging/'+schema_name.lower()+'/'+table_name.lower()+'/processed_date='+partition_date+'/'\r\n",
					"dq_out_path = 'abfss://daigcoanalyticsstorage@daigcoanalyticsstorage.dfs.core.windows.net/cleansed/'+schema_name.lower()+'/'+table_name.lower()+'/processed_date='+partition_date+'/'\r\n",
					"#dq_check_path = 'abfss://kannainput@jithendra231221.dfs.core.windows.net/control_file_A/dqtable.csv'"
				],
				"attachments": null,
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"microsoft": {
						"language": "scala"
					}
				},
				"source": [
					"%%spark\r\n",
					"\r\n",
					"val df=spark.read.synapsesql(\"dai_gco_analytics_dp.control_schema.dq_constraints\")\r\n",
					"df.createOrReplaceTempView(\"dq_constraints\")"
				],
				"attachments": null,
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"df = spark.sql(\"\"\"select * from dq_constraints where status = 'active'\"\"\")"
				],
				"attachments": null,
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def dqiterator (table_name,dq_rules):\r\n",
					"  #dq_rules=dq_rules.split(\",\")\r\n",
					"  df=spark.read.format(\"delta\").load(dq_in_path)\r\n",
					"  count = df.count()\r\n",
					"  df=df.withColumn(\"dq_check\",lit(1))\r\n",
					"  dq_rules=dq_rules\r\n",
					"  dq=dq_rules[0].split(\":\")\r\n",
					"  dq_rule=dq[1]\r\n",
					"  print(dq_rule)\r\n",
					"  if dq_rule==\"null_chk\":\r\n",
					"    for column in  dq_rules:\r\n",
					"        columns=column.split(\":\")\r\n",
					"        column_nm=columns[0]\r\n",
					"        df=df.withColumn(\"dq_check\",when(col(column_nm).isNull(),0).when(col(column_nm)==\" \",0).otherwise(col(\"dq_check\")))\r\n",
					"  elif dq_rule==\"numeric_value_chk\":\r\n",
					"    for column in  dq_rules:\r\n",
					"        columns=column.split(\":\")\r\n",
					"        column_nm=columns[0]\r\n",
					"        df=df.withColumn(\"dq_check\",when(~ col(column_nm).rlike(\"^[0-9]*$\"),0).when(col(column_nm)==\" \",0).otherwise(col(\"dq_check\")))\r\n",
					"  df.write.format(\"delta\").mode(\"overwrite\").save(dq_out_path)\r\n",
					"  return count"
				],
				"attachments": null,
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"from pyspark.sql.functions import *\r\n",
					"import pandas\r\n",
					"\r\n",
					"#processedFileList=df.select(\"table_name\").distinct()\r\n",
					"#processed_file_list = list(processedFileList.toPandas()[\"table_name\"])\r\n",
					"#for table_name in processed_file_list:\r\n",
					"dq_rules=list(df.filter(col(\"table_name\")==table_name).select(\"dq_rules\").toPandas()[\"dq_rules\"])\r\n",
					"dq_rules= [dq_rule for sublist in  dq_rules for dq_rule in sublist.split(\",\")]\r\n",
					"print(dq_rules)\r\n",
					"print(table_name)\r\n",
					"staging_layer_count = dqiterator(table_name,dq_rules)\r\n",
					"#print(processed_file_list)"
				],
				"attachments": null,
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"cleansed_count_df = spark.read.format(\"delta\").load(dq_out_path)\r\n",
					"clean_layer_count = cleansed_count_df.count()"
				],
				"attachments": null,
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"row_count = str(staging_layer_count)+'-'+str(clean_layer_count)"
				],
				"attachments": null,
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"mssparkutils.notebook.exit(row_count)"
				],
				"attachments": null,
				"execution_count": null
			}
		]
	}
}